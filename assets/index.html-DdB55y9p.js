import{_ as e,c as r,b as a,o}from"./app-GpZKBnvo.js";const d={};function i(n,t){return o(),r("div",null,t[0]||(t[0]=[a('<p>The processing of video data primarily relies on dataset filtering methods based on evaluation scores.</p><h2 id="pure-video-processing" tabindex="-1"><a class="header-anchor" href="#pure-video-processing"><span>Pure Video Processing</span></a></h2><h3 id="method-categories" tabindex="-1"><a class="header-anchor" href="#method-categories"><span>Method Categories</span></a></h3><table><thead><tr><th>Category Description</th><th>Metric List</th></tr></thead><tbody><tr><td>Based on Video Statistics</td><td>Motion Score</td></tr><tr><td>Based on Pre-trained Models</td><td>FastVQAScorer, FasterVQAScorer, DOVERScorer</td></tr></tbody></table><h3 id="method-overview" tabindex="-1"><a class="header-anchor" href="#method-overview"><span>Method Overview</span></a></h3><table><thead><tr><th>Name</th><th>Filtering Metric</th><th>Filtering Dimension</th><th>Scorer Introduction</th><th>Score Range</th></tr></thead><tbody><tr><td>VideoMotionFilter</td><td>Motion Score</td><td>Statistics</td><td>Calculates the magnitude of optical flow vectors between frames as the score</td><td></td></tr><tr><td><a href="https://arxiv.org/abs/2207.02595v1" target="_blank" rel="noopener noreferrer">FastVQAFilter</a></td><td>Pre-trained model Scoring</td><td>Model</td><td>Scorer based on Video Swin Transformer, incorporating the Fragment Sampling module, which improves accuracy and speed</td><td>[0,1]</td></tr><tr><td><a href="https://arxiv.org/abs/2210.05357" target="_blank" rel="noopener noreferrer">FasterVQAFilter</a></td><td>Pre-trained model Scoring</td><td>Model</td><td>An optimized version of FastVQAScorer, with improvements to the Fragment Sampling module, achieving significant speed enhancements</td><td>[0,1]</td></tr><tr><td><a href="https://arxiv.org/abs/2211.04894" target="_blank" rel="noopener noreferrer">DOVERFilter</a></td><td>Pre-trained model scoring</td><td>Model</td><td>Based on FastVQAScorer, it provides scores from both technical and aesthetic perspectives</td><td></td></tr></tbody></table><h2 id="video-text-processing" tabindex="-1"><a class="header-anchor" href="#video-text-processing"><span>Video-Text Processing</span></a></h2><table><thead><tr><th>Category Description</th><th>Metric List</th></tr></thead><tbody><tr><td>Based on pre-trained vision-language models</td><td>EMScore, PAC-S</td></tr></tbody></table><table><thead><tr><th>Name</th><th>Filtering Metric</th><th>Filtering Dimension</th><th>Scorer Introduction</th><th>Score Range</th></tr></thead><tbody><tr><td><a href="https://arxiv.org/abs/2111.08919" target="_blank" rel="noopener noreferrer">EMScorer</a></td><td>Video-Text Similarity Scoring</td><td>Model</td><td>A video-text scorer based on CLIP, supporting both with-reference and no-reference scoring.</td><td>[0,1]</td></tr><tr><td><a href="https://arxiv.org/abs/2303.12112" target="_blank" rel="noopener noreferrer">PACScorer</a></td><td>ideo-Text Similarity Scoring</td><td>Model</td><td>A video-text scorer based on CLIP, with tuned CLIP Encoder on top of EMScore</td><td>[0,1]</td></tr></tbody></table>',9)]))}const c=e(d,[["render",i]]),h=JSON.parse('{"path":"/en/guide/nz3gjjdu/","title":"Video Data Processors","lang":"en-US","frontmatter":{"title":"Video Data Processors","createTime":"2025/06/09 11:43:25","permalink":"/en/guide/nz3gjjdu/"},"readingTime":{"minutes":0.76,"words":227},"git":{"createdTime":1749441278000,"updatedTime":1750133178000,"contributors":[{"name":"Sunnyhaze","username":"Sunnyhaze","email":"mxch1122@126.com","commits":1,"avatar":"https://avatars.githubusercontent.com/Sunnyhaze?v=4","url":"https://github.com/Sunnyhaze"},{"name":"Ma, Xiaochen","username":"","email":"mxch1122@126.com","commits":2,"avatar":"https://gravatar.com/avatar/c86bc98abf428aa442dfc12c76e70e324a551ebc637e5ed6634d60fbd3811221?d=retro"}]},"filePathRelative":"en/notes/guide/operators/video_process.md","headers":[]}');export{c as comp,h as data};
